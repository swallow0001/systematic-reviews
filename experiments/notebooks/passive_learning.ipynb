{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Passive learning\n",
    "\n",
    "This notebook is used to find the best results by using passive learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "sys.path.insert(0, os.path.join('..', 'examples'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# sklearn functions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             precision_score,\n",
    "                             recall_score, \n",
    "                             classification_report, \n",
    "                             f1_score, \n",
    "                             make_scorer)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# project specific functions\n",
    "from utils import load_ptsd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the texts and their corresponding labels\n",
    "texts, labels = load_ptsd_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {'count_vect__max_features': np.arange(4000, 6000, 500),\n",
    "     'count_vect__min_df': np.arange(0.0, 0.1, 0.05),\n",
    "     'count_vect__max_df': np.arange(0.6, 0.8, 0.05),\n",
    "     'tfidf': [None, TfidfTransformer()]}\n",
    "]\n",
    "\n",
    "clf_nb = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score, average='weighted'),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_nb.fit(texts, labels)\n",
    "prediction = clf_nb.predict(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "means = clf_nb.cv_results_['mean_test_score']\n",
    "stds = clf_nb.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_nb.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "Pipeline(memory=None,\n",
      "     steps=[('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8000000000000002, max_features=5500,\n",
      "        min_df=0.0, ngram_range=(1, 1), preprocessor=None, stop_wo...bulary=None)), ('tfidf', None), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n"
     ]
    }
   ],
   "source": [
    "print(clf_nb.best_params_)\n",
    "print(clf_nb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "F1 score:  0.9890778216977931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99      5037\n",
      "          1       0.35      0.97      0.52        40\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"results\")\n",
    "print(\"F1 score: \", f1_score(labels, prediction, average='weighted'))\n",
    "print(classification_report(labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4966   71]\n",
      " [   1   39]]\n",
      "0.9858183966909593\n",
      "0.9947149350340608\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, prediction))\n",
    "print(recall_score(labels, prediction, average='weighted'))\n",
    "print(precision_score(labels, prediction, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SVC\n",
    "\n",
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 13.5min finished\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {'count_vect__max_features': np.arange(4000, 6000, 500),\n",
    "     'count_vect__min_df': np.arange(0.0, 0.1, 0.05),\n",
    "     'count_vect__max_df': np.arange(0.6, 0.8, 0.05),\n",
    "     'tfidf': [None, TfidfTransformer()], \n",
    "     'clf__C': [0.8, 1.0, 1.2]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf_svc = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score, average='weighted'),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_svc.fit(texts, labels)\n",
    "prediction_svc = clf_svc.predict(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 0.8, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.0, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.6, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.65, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7000000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.7500000000000001, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 4500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5000, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.0, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': None}\n",
      "0.988 (+/-0.001) for {'clf__C': 1.2, 'count_vect__max_df': 0.8000000000000002, 'count_vect__max_features': 5500, 'count_vect__min_df': 0.05, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n"
     ]
    }
   ],
   "source": [
    "means = clf_svc.cv_results_['mean_test_score']\n",
    "stds = clf_svc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_svc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 0.8, 'count_vect__max_df': 0.6, 'count_vect__max_features': 4000, 'count_vect__min_df': 0.0, 'tfidf': None}\n",
      "Pipeline(memory=None,\n",
      "     steps=[('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.6, max_features=4000, min_df=0.0,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "     ...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "print(clf_svc.best_params_)\n",
    "print(clf_svc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "F1 score:  0.9881975769705756\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5037\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.98      0.99      0.99      5077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"results\")\n",
    "print(\"F1 score: \", f1_score(labels, prediction_svc, average='weighted'))\n",
    "print(classification_report(labels, prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5037    0]\n",
      " [  40    0]]\n",
      "0.9921213314949774\n",
      "0.9843047364073668\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, prediction_svc))\n",
    "print(recall_score(labels, prediction_svc, average='weighted'))\n",
    "print(precision_score(labels, prediction_svc, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
